#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jun 13 14:52:36 2023

@author: vitor
"""

import re
import os
import time
import csv
import pdb
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import ElementClickInterceptedException, TimeoutException, NoSuchElementException, StaleElementReferenceException
from custom_selenium_classes import CustomDriver


class BuserScraper:
    # Atualizar o driver_path de acordo com o caminho local para o chromedriver
    def __init__(self, driver_path='/usr/local/bin/chromedriver'):
        self.driver_path = driver_path
        self.driver = None
        
    def scrape(self, departure_location_list, arrival_location_list, departure_date_list, return_date_list=None):
        
        if len(departure_location_list) != len(arrival_location_list):
            raise ValueError("As listas de locais de chegada e partida devem ter o mesmo tamanho.")
        
        if return_date_list is None:
            return_date_list = [float('nan') for _ in range(len(departure_date_list))]
        elif len(return_date_list) != len(departure_date_list):
            raise ValueError("As listas de datas de chegada e partida devem ter o mesmo tamanho.")
        
        self._initialize_driver()
        
        # Verifique se há um arquivo de progresso salvo
        try:
           with open("progress.txt", "r") as progress_file:
               progress_data = progress_file.read().strip().split(',')
               start_index = int(progress_data[0])
               search_id = int(progress_data[1])
        except FileNotFoundError:
           start_index = 0
           search_id = 1
        
        scraping_results = []
        
        # Abra o arquivo no modo de append para escrever os resultados
        with open("results_search.csv", "a", newline="") as file:
            writer = csv.writer(file)
            
            # Se não houver progresso salvo, escreva o cabeçalho no arquivo
            if start_index == 0:
                writer.writerow(['Company Name', 'Search ID', 'Promotion Price', 'No Promotion Price', 'Departure Date',
                                 'Departure Time', 'Arrival Time', 'Arrival Date', 'Arrival Location', 'Departure Location', 'Class'])
            
            # Inicie o loop a partir do índice salvo ou 0 se nenhum progresso for salvo
            for index in range(start_index, len(departure_location_list)):
                departure_location = departure_location_list[index]
                arrival_location = arrival_location_list[index]
                departure_date = departure_date_list[index]
                return_date = return_date_list[index]
                
                try:
                    self._search(departure_location, arrival_location, departure_date, return_date)
                    self.driver.implicitly_wait(10)
                    scrape_results = self._scrape_search_result(return_date)
                    if scrape_results:
                        for scrape_result in scrape_results:
                            scrape_result_len = len(scrape_result['company_name'])
                            scrape_result['search_id'] = [search_id for _ in range(scrape_result_len)]
                        scraping_results += scrape_results
                        search_id += 1
                except Exception as e:
                    # Se ocorrer um erro, salve o índice atual para retomar posteriormente
                    with open("progress.txt", "w") as progress_file:
                        progress_file.write(f"{index},{search_id}")
                    
                    # Escreva os resultados gerados até o momento no arquivo antes de ocorrer o erro
                    self._write_results_csv(writer, scraping_results)
    
                    raise e
                    
            # Escreva os resultados finais gerados no arquivo
            self._write_results_csv(writer, scraping_results)
                          
        # Remova o arquivo de progresso em caso de erro
        if os.path.exists("progress.txt"):
            os.remove("progress.txt") 
            
        
        self._quit_driver()
        
    def _write_results_csv(self, writer, scraping_results):
     
        for scrape_result in scraping_results:
            scrape_result_len = len(scrape_result['company_name'])
            
            for i in range(scrape_result_len):
                writer.writerow([
                    scrape_result['company_name'][i],
                    scrape_result['search_id'][i],
                    scrape_result['promotion_price'][i],
                    scrape_result['no_promotion_price'][i],
                    scrape_result['departure_date'][i],
                    scrape_result['departure_time'][i],
                    scrape_result['arrival_time'][i],
                    scrape_result['arrival_date'][i],
                    scrape_result['arrival_location'][i],
                    scrape_result['departure_location'][i],
                    scrape_result['class'][i]
                ])    

    # Iniciando o chromedriver
    def _initialize_driver(self):
        if not self.driver:
            self.driver = webdriver.Chrome(executable_path=self.driver_path)
            self.driver = CustomDriver(self.driver)
            return 
        
        if not self._is_driver_alive():
            self.driver = webdriver.Chrome(executable_path=self.driver_path)
            self.driver = CustomDriver(self.driver)
            return

    def _is_driver_alive(self):
        try:
           self.driver.current_url
           return True
        except:
           return False 
            
    
    # Encerrando o chromedriver
    def _quit_driver(self):
        if self.driver:
            self.driver.quit()
    
    # Abrindo a página do buser
    def _open_buser_site(self):
        self._initialize_driver()
        if self.driver.current_url != 'https://www.buser.com.br/':
            self.driver.get('https://www.buser.com.br/')
            self.driver.implicitly_wait(10)
        # if self.driver.find_element(By.XPATH, "//div[@class='m-wrapper']"):
        #     close_button = self.driver.find_element(By.XPATH, "//button[contains(text(), 'Fechar')]")
        #     close_button.click()
    
    # Realizando a pesquisa dado na página inicial do Buser
    def _search(self, departure_location, arrival_location, departure_date, return_date):
        self._open_buser_site()
        
        while True:
            try:
                # Encontrar elementos de entrada
                input_origin_element = self.driver.find_element(By.ID, "origem")
                input_arrival_element = self.driver.find_element(By.ID, "destino")
                input_departure_date_element = self.driver.find_element(By.CSS_SELECTOR, 'input[placeholder="Ida"]')
                
                # Preencher informações de origem e destino
                self._select_location(input_origin_element, departure_location, 'origem-list')
                time.sleep(1)
                while True:
                    self._select_location(input_arrival_element, arrival_location, 'destino-list')
                    arrival_text = input_arrival_element.get_attribute('data-maska-value')
                    if arrival_text and departure_location.lower() not in arrival_text.lower():
                        break
                    else:
                        input_arrival_element.clear()

                
                input_departure_date_element.click()
                self._select_date(departure_date)
        
                # Preencher data de partida
                #input_departure_date_element.send_keys(departure_date)
                
                # Se caso houver um return_date específicado
                # valores nulos não são iguais a eles mesmos no python
                if return_date == return_date:
                    pdb.set_trace()
                    input_return_date_element = self.driver.find_element(By.CSS_SELECTOR, 'input[placeholder="Ida"]')
                    input_return_date_element.click()
                    self._select_date(return_date)
            
                # # Clicar no botão de pesquisa
                search_button = self.driver.find_element(By.CSS_SELECTOR, 'button[aria-label="Buscar"]')

                search_button.click()
                pdb.set_trace()
                
                return True
            except (StaleElementReferenceException, ElementClickInterceptedException, NoSuchElementException):
                pdb.set_trace()
                self._close_mwrapper()
            
            
    def _close_mwrapper(self):
        m_wrapper = self.driver.find_element(By.XPATH, "//div[@class='m-wrapper']")
        close_button = m_wrapper.find_element(By.XPATH, "//button[@aria-label='Fechar']")        
        close_button.click()        
        
    def _select_date(self, data):
        dia, mes, ano = map(int, data.split('/'))
        data_atual = datetime.now().date()
        data_desejada = datetime(ano, mes, dia).date()
        dif_meses = (data_desejada.year - data_atual.year) * 12 + (data_desejada.month - data_atual.month)
        botao_proximo_mes = self.driver.find_element(By.CSS_SELECTOR, 'button[data-testid="next"]')
        for _ in range(dif_meses):
            botao_proximo_mes.click()
            
        botao_dia = self.driver.find_element(By.XPATH, f'//button[@data-testid={dia}]')
        # Clique no botão do dia desejado
        botao_dia.click()
        
    # Scraping os resultados da pesquisa
    def _scrape_search_result(self, return_date=float('nan')):
        has_return_date = return_date == return_date
        
        html = self.driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        search_results = soup.find(attrs={"data-testid": "search-results"})
        # Não há resultado na pesquisa
        if search_results == None:
            return False
        
        containers = search_results.find_all(attrs={"data-testid": "search-item-container"})
        results = {
            'company_name': [],
            'promotion_price': [],
            'no_promotion_price': [],
            'departure_date': [],
            'departure_time': [],
            'arrival_time': [],
            'arrival_date': [],
            'arrival_location': [],
            'departure_location': [],
            'class': []
        }
        for container in containers:
            # Obter o nome da empresa
            company_element = container.find(class_=self.company_regex)
            company_name = company_element.get('data-content')

            # Obter preços (tanto de promoção quanto sem promoção)
            price_element = container.find(class_=self.price_regex)
            promotion_element = price_element.find('span', {'data-testid': 'is-promotion'})
            no_promotion_element = price_element.find('span', {'data-testid': 'is-not-promotion'})

            if not promotion_element:
                promotion_price = None
            else:
                promotion_text = promotion_element.text
                promotion_price = self._get_number_from_price(promotion_text)
                
            no_promotion_text = no_promotion_element.get_text(strip=True)
            no_promotion_price = self._get_number_from_price(no_promotion_text)
            
            # Obter informações de data e hora de partida e retorno
            date_element = container.find(class_=self.hour_regex)
            departure_element = date_element.find("time", class_="departure-time")
            departure_date_string = departure_element.get('data-date')
            departure_date = datetime.strptime(departure_date_string, "%Y-%m-%d")
            departure_time = departure_element.get_text(strip=True)

            arrival_element = date_element.find("time", class_="return-time")
            arrival_element_list = arrival_element.get_text(strip=True).split('+')
            arrival_time = arrival_element_list[0]
            plus_days = int(arrival_element_list[1][0]) if len(arrival_element_list) > 1 else 0

            arrival_date_unformatted = departure_date + timedelta(days=plus_days)
            arrival_date = arrival_date_unformatted.strftime("%Y-%m-%d")

            # Obter informações de localização
            location_element = container.find(class_=re.compile(r"\w*bus-station"))
            departure_location_element = location_element.find(class_='station-departure')
            departure_location = departure_location_element.get_text(strip=True)
            arrival_location_element = location_element.find(class_='station-arrival')
            arrival_location = arrival_location_element.get_text(strip=True)
            
            # Obter informações da classe
            class_element = container.find(class_=self.class_regex)
            class_text = class_element.text
            
            # Adicionar resultados à estrutura de dados
            results['company_name'].append(company_name)
            results['no_promotion_price'].append(no_promotion_price)
            results['promotion_price'].append(promotion_price)
            results['departure_time'].append(departure_time)
            results['departure_date'].append(departure_date)
            results['arrival_time'].append(arrival_time)
            results['arrival_date'].append(arrival_date)
            results['arrival_location'].append(arrival_location)
            results['departure_location'].append(departure_location)
            results['class'].append(class_text)
        
        results_len = len(results['company_name'])

        if has_return_date:
            while True:
                try:
                    self._change_to_return_options()
                except (NoSuchElementException, ElementClickInterceptedException):
                    self.driver.refresh()
                    continue
                else:
                    break
            results_departure = results
            results_departure['has_return'] = [True for _ in range(results_len)]
            results_departure['type'] = ['Departure' for _ in range(results_len)]
            results_return = self._scrape_search_result()[0]
            results_return_len = len(results_return['company_name'])
            results_return['has_return'] = [True for _ in range(results_return_len)]
            results_return['type'] = ['Return' for _ in range(results_return_len)]
            results = [results_return, results_departure]
            return results

        else:   
            results['has_return'] = [False for _ in range(results_len)]
            results['type'] = ['Departure' for _ in range(results_len)]
            return [results]
    
    def _change_to_return_options(self):
        select_button = self.driver.find_element(By.XPATH, "//button[contains(text(), 'Selecionar')]")
        select_button.click()
        #wait = WebDriverWait(self.driver, 10)
        seat_items = self.driver.find_elements(By.CSS_SELECTOR, '[data-testid="seatmap-item"]')
        for seat_item in seat_items:
           seat_number_label = seat_item.find_element(By.CSS_SELECTOR, '.seat-number-label')
           if seat_number_label.text:
               try:
                   seat_item.click()
                   break
               except ElementClickInterceptedException:
                   print("Clique interceptado. Tentando outro elemento...")
                   continue
        self._click_continue_booking()
        self._wait_for_page_load()
        return True
    
    def _wait_for_page_load(self):
        try:
            WebDriverWait(self.driver, 10).until(EC.staleness_of(self.driver.find_element(By.XPATH, '//div[contains(text(), "Reservando seu assento")]')))
            print("Página totalmente carregada. Continue a raspagem.")
        except TimeoutException:
            print("Tempo limite de espera excedido. A página pode não ter sido totalmente carregada.")

    def _click_continue_booking(self):
        continue_button = self.driver.find_element(By.CSS_SELECTOR, '.continue-booking')
        self.driver.execute_script("arguments[0].click();", continue_button)
        
    def _select_location(self, input_element, location, ul_class):
        while True:
            try:
                input_element.send_keys(location)
                #pdb.set_trace()
                suggestion_list = WebDriverWait(self.driver, 10).until(
                    EC.visibility_of_element_located((By.ID, f'{ul_class}'))
                    )
                # Clicar na primeira opção da lista
                first_option = suggestion_list.find_element(By.TAG_NAME, 'li')
                first_option.click()
                return True
            except (StaleElementReferenceException, ElementClickInterceptedException, NoSuchElementException):
                self._close_mwrapper()
                
                
    def _get_number_from_price(self, price_text):
        return float(
            price_text.replace('R$', '').replace('\xa0', '')
            .replace('.', '').replace(",", ".")
            )

test = BuserScraper()
departure_location = 'Belo Horizonte'
arrival_location = 'Rio de Janeiro'
departure_date = '01/07/2023'
return_date = '01/08/2023'
test._search(departure_location, arrival_location, departure_date, return_date)
